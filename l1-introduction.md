# Introduction

There's been a lot of material on the internet for prompting with articles like "30 prompts everyone has to know". A lot of that has been focused on the ChatGPT web user interface which many people are using to do specific and often one-off tasks. But the power of Large Language Models (LLM) as a developer to that is using API calls to LLM to quickly build software applications. That is still very underappreciated. 

In this guide, some of the potentialities of LLMs, as well as best practices for their use, will be explored. Initially, best practices for the use of LLMs in software development will be introduced. Subsequently, some common use cases will be analyzed: summarizing, inferring, transforming, expanding. Finally, a chatbot will be created using an LLM. 

In the development of Large Language Models, or LLMs, two types of LLMs have been identified, which will be referred to as "Base LLMs" and "Instruction-Tuned LLMs" here. Base LLMs have been trained to predict the following word based on the text data used for training, often derived from a large amount of data collected from the internet and other sources, in order to determine the most likely following word. For instance, if this input were given: "Once upon a time there was a unicorn", the LLM might complete the sentence, that is, it might predict that the following words are "that lived in a magical forest with all its unicorn friends". But if you were to prompt it with "What is the capital of France?" then based on what articles on the internet might have it's quite possible that a Base LLMs will complete this with "What is the France's largest city?", "What is the France's population?", "What is the currency of France?" and so on because articles on the internet could quite plausibly be lists of quiz questions about the country of France.

In contrast, Instruction-Tuned LLMs, which is where a lot of momentum in LLMs research and practice has been going, have been trained to follow instructions. So, if you were to ask it, 'What is the capital of France?', it is much more likely to output something like 'The capital of France is Paris.' The way that Instruction-Tuned LLMs are typically trained is as follows: you start off with a Base LLM that has been trained on a huge amount of text data, and further train it by fine-tuning it with inputs and outputs that consist of instructions and good attempts to follow those instructions. Then, it is often further refined using a technique called RLHF (reinforcement learning from human feedback) to make the system better able to be helpful and follow instructions. Because Instruction-Tuned LLMs have been trained to be helpful, honest, and harmless, they are less likely to generate problematic text such as toxic outputs compared to Base LLMs. As a result, many practical usage scenarios have been shifting towards Instruction-Tuned LLMs.

Some of the best practices you find on the internet may be more suited for a Base LLMs. But for most practical applications today, it would be recommendable for most people instead focus on Instruction-Tuned LLMs. These are easier to use and also, because of the work of OpenAI and other LLM companies, are becoming safer and more aligned. So, this guide will focus on best practices for Instruction-Tuned LLMs, which is what is recommended for most of your applications.

So, when you use an Instruction-Tuned LLMs, think of giving instructions to another person. Say someone that's smart but doesn't know the specifics of your task. So, when an LLM doesn't work, sometimes it's because the instructions weren't clear enough. For example, if you were to say, 'Please write me something about Alan Turing,' well, in addition to that, it can be helpful to be clear about whether you want the text to focus on his scientific work, his personal life, his role in history, or something else. And if you specify what you want the tone of the text to be, should it take on the tone like a professional journalist would write? Or is it more of a casual note that you dash off to a friend that hopes the LLM generate what you want? And of course, if you picture yourself asking, say, a fresh college graduate to carry out this task for you, if you can even specify what snippets of text they should read in advance to write this text about Alan Turing, then that even better sets up that fresh college grad for success to carry out this task for you.

So, in the next chapters, you see examples of how to be clear and specific, which is an important principle of prompting LLMs. And you also learn a second principle of prompting that is giving LLMs time to think. So with that, let's go on to the next chapter.